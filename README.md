# ğŸ“° Fake News Detector

This is my **Fake News Detector** â€” a fully functional web application that uses **Machine Learning** to classify news articles as **Real** or **Fake**.  
I developed it completely from scratch, starting from **data preprocessing** and **model training**, to **API creation**, **web interface**, and **full production deployment** on my VPS with **Gunicorn + Apache + HTTPS**.

---


## ğŸš€ Live Demo
**Web Interface:** [https://haseebsagheer.com/fake-news-detector](https://haseebsagheer.com/fake-news-detector)  
**API Endpoint:** `/predict`


---

## ğŸ“Œ Project Motivation

Misinformation spreads faster than ever, and it's not just a social issue â€” it's a data problem.  
As a Data Scientist in training, I wanted to create something that:
- Tackles a real-world problem
- Involves a full **end-to-end ML pipeline**
- Challenges me beyond Jupyter Notebooks, pushing into **production deployment**
- Strengthens my **Flask, API design, server administration, and ML deployment skills**

This was also a way to **add a strong real-world AI project to my portfolio**, something that potential employers and clients can interact with live.

---

## ğŸ“Š Dataset Details

I used the **Fake News Detection Dataset** from Kaggle by **Emine Yetim**.

Dataset link: [Kaggle â€“ Fake News Detection Datasets](https://www.kaggle.com/datasets/emineyetm/fake-news-detection-datasets)

It consists of two CSV files:
- **`fake.csv`** â†’ Articles labeled as "Fake"
- **`true.csv`** â†’ Articles labeled as "Real"

Each file has:
- **title** â€” headline/title of the news article
- **text** â€” the body/content of the news article
- **subject** â€” category/subject of the article
- **date** â€” publication date

---

## ğŸ›  Technologies Used

### **Backend**
- Python 3.10
- Flask (API and Web Interface)
- Gunicorn (WSGI application server)
- Apache (Reverse Proxy + SSL)
- Systemd (service manager for auto-start)

### **Machine Learning**
- scikit-learn
- pandas, numpy
- joblib (model persistence)
- LinearSVC (Support Vector Machine with linear kernel)
- TF-IDF Vectorizer

### **Frontend**
- HTML, CSS (custom, responsive design)
- Simple, minimal interface for usability

### **Deployment & Security**
- Ubuntu VPS
- Apache VirtualHost configurations for multiple apps
- Let's Encrypt SSL for HTTPS
- Reverse Proxy with ProxyPass/ProxyPassReverse

---

## ğŸ”„ Development Workflow

### 1ï¸âƒ£ **Data Preprocessing**
I started by loading both CSV files into pandas DataFrames and:
- Merged them with labels: `1` for real, `0` for fake
- Removed duplicates and empty rows
- Lowercased all text
- Removed punctuation and special characters
- Tokenized words
- Removed stopwords
- Lemmatized tokens for normalization
- Merged `title` and `text` into a single column for better context

---

### 2ï¸âƒ£ **Feature Extraction**
- Used **TF-IDF Vectorization** to convert text into numerical features
- Tuned vectorizer parameters (`max_df`, `min_df`, `ngram_range`) to balance dimensionality and context capture

---

### 3ï¸âƒ£ **Model Selection & Training**
- Tried several models: Logistic Regression, Random Forest, Naive Bayes, LinearSVC
- Selected **LinearSVC** for:
  - Speed
  - High accuracy
  - Low resource usage in production
- Trained with TF-IDF vectors
- Saved entire pipeline (`TF-IDF + LinearSVC`) with `joblib`

---

### 4ï¸âƒ£ **Building the Flask App**
The app has **two main components**:
1. **Web UI** â€” user-friendly interface where users paste a news article
2. **API Endpoint (`/predict`)** â€” accepts POST JSON requests and returns predictions

**Example API Request:**
```bash
curl -X POST https://haseebsagheer.com/fake-news-detector/predict \
  -H "Content-Type: application/json" \
  -d '{"title":"Breaking News","text":"Some news content..."}'
```
# Fake News Detector

## Example API Response
```json
{
  "label": "Real",
  "len_chars": 150,
  "model": "LinearSVC_TFIDF",
  "score": 0.85
}
```

---

## ğŸŒŸ Features
- âœ… **Real-Time Classification** â€” returns prediction instantly  
- âœ… **API Access** â€” usable in external applications  
- âœ… **User-Friendly Interface** â€” paste text and click predict  
- âœ… **Secure (HTTPS)** â€” fully encrypted connections  
- âœ… **Multiple Apps on One VPS** â€” CV Generator + Fake News Detector  
- âœ… **Error Handling** â€” proper JSON responses for invalid requests  

---

## ğŸš€ Live Demo
**Web Interface:** [https://haseebsagheer.com/fake-news-detector](https://haseebsagheer.com/fake-news-detector)  
**API Endpoint:** `/predict`

---

## âš”ï¸ Challenges I Overcame

### Multiple Flask Apps on Same VPS
My CV Generator was already deployed. Setting up a second Flask app without breaking the first required careful Apache and Gunicorn configuration.

### Apache Reverse Proxy Issues
At first, the frontend got `SyntaxError: Unexpected token '<'...` errors.  
I fixed it by correcting `ProxyPassMatch` rules and ensuring JSON was passed correctly.

### Persistent Service
Initially, I had to manually start Gunicorn after every reboot.  
Learned how to use `systemd` to create a permanent service.

### CORS & SSL
Configured HTTPS for secure API calls and avoided mixed-content errors in browsers.

---

## ğŸ“š What I Learned
- End-to-End ML Deployment â€” from data preprocessing to production API  
- Flask Best Practices for building maintainable apps  
- Gunicorn & Apache Reverse Proxy integration  
- Linux Server Management â€” virtual environments, services, ports, logs  
- Model Optimization for real-time predictions  
- Debugging server-side JSON parsing issues  

---

## ğŸ“‚ Project Structure
```plaintext
fake-news-detector/
â”‚
â”œâ”€â”€ app/                   
â”‚   â”œâ”€â”€ app.py             # Flask app
â”‚   â”œâ”€â”€ templates/         # HTML UI
â”‚   â”œâ”€â”€ static/            # CSS files
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ best_pipeline.joblib  # Trained ML model
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ… Certifications
- **Credly Profile:** [https://www.credly.com/users/haseeb-sagheer](https://www.credly.com/users/haseeb-sagheer)  
- **Coursera Profile:** [https://www.coursera.org/learner/haseeb-sagheer](https://www.coursera.org/learner/haseeb-sagheer)

---

## ğŸ™Œ Acknowledgments
- Dataset by [Emine Yetim â€“ Kaggle](https://www.kaggle.com)  
- ChatGPT â€” only used for HTML & CSS help for the UI. All backend, ML, API, and deployment were coded by me.

---

## ğŸ“ Contact
- ğŸ“§ **Email:** engrhaseebsagheer@gmail.com  
- ğŸ“± **Phone/WhatsApp:** +92 308 2496103  
- ğŸ’¼ **LinkedIn:** [https://linkedin.com/in/haseeb-sagheer](https://linkedin.com/in/haseeb-sagheer)  
- ğŸ™ **GitHub:** [https://github.com/engrhaseebsagheer](https://github.com/engrhaseebsagheer)  
- ğŸŒ **Portfolio:** [https://haseebsagheer.com](https://haseebsagheer.com)  

---


